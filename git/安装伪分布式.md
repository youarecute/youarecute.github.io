安装hadoop(单节点:一台电脑)
1.先关闭防火墙
2.安装jdk和hadoop
3.root设置visudo,使用户hadoop能够修改/etc/profile(hadoop[bin和sbin])
export HADOOP_HOME=/home/hadoop/hadoop-2.7.3
PATH=$PATH:$HOME/.local/bin:$HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export JAVA_HOME=/home/hadoop/jdk1.8.0_181
PATH=$PATH:$JAVA_HOME/bin

4.测试mapreduce(hadoop jar jar包位置 执行命令 管理的数据位置 输出结果的位置 执行命令规则)
5.查看输出结果的文件夹  (cat 文件夹/*  , 其实展示的是part-r-00000)

jar包位置(hadoop文件夹/share/hadoop/mapreduce/hadoop-mapreduce-example)



(伪分布式 [一台电脑上模拟的分布式] )
安装步骤:
1.cd ~/hadoop-2.7.3/etc/hadoop/
2.编辑hadoop-env.sh(暂时不管,直接退出)
3.vim core-site.xml(在里面configuration中插入下属字段)
<property>  
        <name>hadoop.tmp.dir</name>  //存放临时文件
        <value>/usr/local/hadoop/tmp</value> //路径
</property>  
<property>  
        <name>fs.defaultFS</name>    // 设置默认的文件系统
        <value>hdfs://192.168.8.130:9000</value> //namenode所在电脑的ip地址,伪分布式都在一台电脑上,默认9000端口 
</property> 
4.vim hdfs-site.xml
<property>    
        <name>dfs.replication</name>   //设置备份的 (暂时删除不管)
        <value>1</value>    
</property>    
<property>    
        <name>dfs.namenode.name.dir</name>   //namenode 
        <value>file:/usr/local/hadoop/dfs/name</value> //元数据存储位置   
</property>    
<property>    
        <name>dfs.datanode.data.dir</name>    
        <value>file:/usr/local/hadoop/dfs/data</value>    
</property>
5.vim yarn-site.xml
<property>  
	<name>mapreduce.framework.name</name>  //yarn工作的
	<value>yarn</value>  
</property>  
  
<property>  
	<name>yarn.nodemanager.aux-services</name>  
	<value>mapreduce_shuffle</value>  
</property>  
6.cp mapred-site.xml.template mapred-site.xml
7.vim mapred-site.xml
<property>

<name>
mapreduce.framework.name
</name>

<value>
yarn
</value>

</property>
8.格式化HDFS
hadoop namenode -format
9.start-all.sh
yes
用户密码
10.修改hadoop-env.sh
JAVA_HOME
11.start-all.sh
一直密码
12.jps
总共6项
(如果不全就stop-all.sh,再重启)

如果时间过长,自动关闭了几项怎么办??
st查找命令
stop-dfs.sh
start-dfs.sh
start-yarn.sh

namenode启动不了??
1.看日志
/home/hadoop/hadoop版本/logs  日志文件
第二个的是用户
2.
端口占用(找到占用的进程,root权限)
netstat -tunlp|grep 端口号(| java)
3.
杀死进程(root权限),来释放端口,解决端口占用的问题
kill -9 进程
4.
再次开启namenode





HDFS(namenode元数据  datanode存储的数据)
数据-->namenode-->决定存储在哪个datanode-->数据-->datanode
